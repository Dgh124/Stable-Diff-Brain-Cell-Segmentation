{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyO5kP66Xvw5AxZRMbI9cVeb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2boN11pvHQ5_","executionInfo":{"status":"ok","timestamp":1737875098706,"user_tz":300,"elapsed":24974,"user":{"displayName":"Dahirou Dabo Harden","userId":"03178038846286108204"}},"outputId":"a5d31e2c-bebd-4e8f-9e2d-97bce4db5c8b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n","from PIL import Image\n","\n","class ImageDataset(Dataset):\n","    def __init__(self, image_dir, transform=None):\n","        self.image_dir = image_dir\n","        self.image_filenames = sorted(os.listdir(image_dir))\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_filenames)\n","\n","    def __getitem__(self, idx):\n","        image_path = os.path.join(self.image_dir, self.image_filenames[idx])\n","        # Convert to grayscale ('L' mode)\n","        image = Image.open(image_path).convert('L')\n","        if self.transform:\n","            image = self.transform(image)\n","        return image"],"metadata":{"id":"0w4ql0GlLLtE","executionInfo":{"status":"ok","timestamp":1737875101932,"user_tz":300,"elapsed":3228,"user":{"displayName":"Dahirou Dabo Harden","userId":"03178038846286108204"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, random_split, Subset\n","import torchvision.transforms as T\n","import os\n","from tqdm import tqdm\n","import random\n","from torch.optim.lr_scheduler import ReduceLROnPlateau"],"metadata":{"id":"wrK1LdcPSe4E","executionInfo":{"status":"ok","timestamp":1737875107206,"user_tz":300,"elapsed":5275,"user":{"displayName":"Dahirou Dabo Harden","userId":"03178038846286108204"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Xt7J-uMvHKtm","outputId":"e00568d1-e5a6-4e98-8b10-5b38829d2e52","executionInfo":{"status":"error","timestamp":1737875214727,"user_tz":300,"elapsed":14378,"user":{"displayName":"Dahirou Dabo Harden","userId":"03178038846286108204"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Current Directory: /content/drive/MyDrive/Stable_diff/train_vae\n"]},{"output_type":"stream","name":"stderr","text":["Epoch [1/25]:   0%|          | 0/805 [00:09<?, ?it/s]\n"]},{"output_type":"error","ename":"TypeError","evalue":"Sequential.forward() takes 2 positional arguments but 3 were given","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-8c61b28e0808>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     train_vae(\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mdata_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Stable_diff/complete_tdata/expanded_dataset\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-8c61b28e0808>\u001b[0m in \u001b[0;36mtrain_vae\u001b[0;34m(data_root, num_epochs, batch_size, lr, momentum, image_size, device)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mrecon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Stable_diff/train_vae/vae_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mx_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_recon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Stable_diff/train_vae/decoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, encoded_features)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# print(f\"\\nX.SHAPE: {x.shape}\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstg1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstg1_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoded_features\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Sequential.forward() takes 2 positional arguments but 3 were given"]}],"source":["# train_vae.py\n","\n","\n","# Specify the path you want to change to\n","new_directory = \"/content/drive/MyDrive/Stable_diff/train_vae\"\n","\n","# Change the current working directory\n","os.chdir(new_directory)\n","\n","# Confirm the directory has changed\n","print(\"Current Directory:\", os.getcwd())\n","\n","from vae_model import VAE  # The combined VAE from above\n","\n","def evaluate(model, dataloader, device):\n","    \"\"\"\n","    Evaluate model on the entire dataloader, returning the average VAE loss.\n","    \"\"\"\n","    model.eval()\n","    total_loss = 0.0\n","    count = 0\n","\n","    with torch.no_grad():\n","        for images in dataloader:\n","            images = images.to(device)\n","            recon, mu, logvar = model(images)\n","            loss = vae_loss_function(recon, images, mu, logvar)\n","            total_loss += loss.item() * images.size(0)\n","            count += images.size(0)\n","\n","    avg_loss = total_loss / count\n","    return avg_loss\n","\n","########################################\n","# 1. Define your VAE loss\n","########################################\n","def vae_loss_function(recon_x, x, mu, logvar):\n","    \"\"\"\n","    Standard VAE Loss = MSE reconstruction + KL divergence.\n","    You can also switch to L1 or BCE for recon, depending on your data range.\n","    \"\"\"\n","    # Reconstruction loss (MSE)\n","    recon_loss = nn.functional.mse_loss(recon_x, x, reduction='mean')\n","\n","    # KL Divergence\n","    # KL = -0.5 * sum(1 + logvar - mu^2 - exp(logvar))\n","    # We'll reduce (mean) across all batch pixels\n","    kld = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n","\n","    return recon_loss + kld\n","\n","########################################\n","# 2. Main training loop\n","########################################\n","def train_vae(\n","    data_root,\n","    num_epochs,\n","    batch_size,\n","    lr,\n","    momentum,\n","    image_size,\n","    device\n","):\n","\n","    # 2.1 Build transforms and dataset\n","    transform = T.Compose([\n","        T.Grayscale(num_output_channels=1),\n","        T.Resize((image_size, image_size)),\n","        T.ToTensor(),\n","        T.Normalize(mean=[0.5], std=[0.5])\n","        # Optionally T.Normalize([0.5], [0.5]) if you want [-1,1] range.\n","    ])\n","    dataset = ImageDataset(image_dir=f'/content/drive/MyDrive/Stable_diff/complete_tdata/expanded_dataset', transform=transform)\n","\n","    overall_ratio = 0.6\n","\n","    subset_indices = random.sample(range(len(dataset)), int(len(dataset) * overall_ratio))\n","    sub_dataset = Subset(dataset, subset_indices)\n","\n","    train_ratio = 0.5\n","\n","    train_len = int(len(sub_dataset) * train_ratio)\n","    val_len = len(sub_dataset) - train_len\n","    train_dataset, val_dataset = random_split(sub_dataset, [train_len, val_len])\n","\n","    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","    model_path = '/content/drive/MyDrive/Stable_diff/train_vae/models/best_model-epoch:2-loss:0.354328.pth'\n","\n","    # 2.2 Initialize model and optimizer\n","    model = VAE().to(device)\n","\n","    # if os.path.exists(model_path):\n","    #     print(\"\\nsuccessfully loaded model\\n\")\n","    #     model.load_state_dict(torch.load(model_path, map_location=device))\n","\n","    cur_lr = prev_lr = lr\n","    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","\n","    scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n","\n","    # best_loss = 0.003076\n","    best_loss = float('inf')\n","    best_model_weights = model.state_dict().copy()\n","\n","\n","    # These counters control reverting weights (mini-patience)\n","    # and early stopping (full patience)\n","    early_stopping = 0\n","    mini_patience = 3   # revert to best weights if no improvement for 3 consecutive epochs\n","    full_patience = 10  # stop training if no improvement for 10 consecutive epochs\n","\n","    step = 0\n","    accumulation_steps = 10\n","\n","    # 2.3 Training loop\n","    for epoch in range(num_epochs):\n","        model.train()\n","        total_loss = 0.0\n","\n","        loader = tqdm(train_dataloader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", leave=True)\n","        for images in loader:\n","            images = images.to(device)  # shape (N,1,H,W)\n","\n","            step += 1\n","\n","            # Forward pass\n","            recon, mu, logvar = model(images)\n","\n","            # Compute loss\n","            loss = vae_loss_function(recon, images, mu, logvar)\n","\n","            total_loss += loss.item() * images.size(0)\n","\n","            # loss = loss / accumulation_steps\n","\n","            # Backprop\n","            # optimizer.zero_grad()\n","            loss.backward()\n","            # optimizer.step()\n","\n","            if (step + 1) % accumulation_steps == 0 or (step + 1) == len(train_dataloader):\n","                loss = loss / accumulation_steps\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","        avg_train_loss = total_loss / len(train_dataloader.dataset)\n","        # Val loss\n","        val_loss = evaluate(model, val_dataloader, device)\n","        print(f\"\\nEpoch [{epoch+1}/{num_epochs}]  \"\n","              f\"Train Loss: {avg_train_loss:.6f}  |  Val Loss: {val_loss:.6f}\")\n","\n","        # 2.4 Print average epoch loss\n","        if val_loss < best_loss:\n","            best_loss = val_loss\n","            best_model_weights = model.state_dict().copy()\n","            print(\"new best model saved\")\n","            torch.save(model.state_dict(), f\"/content/drive/MyDrive/Stable_diff/train_vae/models/best_model-epoch:{epoch}-loss:{val_loss:.6f}.pth\")\n","            early_stopping = 0\n","        else:\n","            early_stopping += 1\n","            if early_stopping >= full_patience:\n","                print(f\"Early stopping triggered at epoch {epoch}\")\n","                break\n","            if early_stopping >= mini_patience:\n","                print(f\"Reverting weights at epoch {epoch}\")\n","                model.load_state_dict(best_model_weights)\n","\n","        # LR scheduler\n","        scheduler.step(val_loss)\n","        cur_lr = scheduler.get_last_lr()[0]\n","        if cur_lr != prev_lr:\n","            print(f\"Learning rate updated: {cur_lr}\")\n","            prev_lr = cur_lr\n","\n","    # 2.5 Save final model (optional)\n","    # torch.save(model.state_dict(), \"train_vae/models\")\n","    print(\"Training finished and model saved.\")\n","    torch.save(model.state_dict(), f\"/content/drive/MyDrive/Stable_diff/train_vae/models/best_model-epoch:{epoch}-loss:{best_loss:.6f}.pth\")\n","\n","if __name__ == \"__main__\":\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    train_vae(\n","        data_root=\"/content/drive/MyDrive/Stable_diff/complete_tdata/expanded_dataset\",\n","        num_epochs=25,\n","        batch_size=5,\n","        lr=1e-4,\n","        momentum=0.9,\n","        image_size=256,\n","        device=device\n","    )\n"]},{"cell_type":"code","source":["import random\n","import matplotlib.pyplot as plt\n","import torch\n","\n","new_directory = \"/content/drive/MyDrive/Stable_diff/train_vae\"\n","\n","# Change the current working directory\n","os.chdir(new_directory)\n","\n","# Confirm the directory has changed\n","print(\"Current Directory:\", os.getcwd())\n","\n","image_size = 256\n","\n","transform = T.Compose([\n","        T.Grayscale(num_output_channels=1),\n","        T.Resize((image_size, image_size)),\n","        T.ToTensor(),\n","        T.Normalize(mean=[0.5], std=[0.5])\n","        # Optionally T.Normalize([0.5], [0.5]) if you want [-1,1] range.\n","    ])\n","\n","from vae_model import VAE  # The combined VAE from above\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# dataset = ImageDataset(image_dir=f'/content/drive/MyDrive/Stable_diff/complete_tdata/expanded_dataset', transform=transform)\n","\n","# Overfitting\n","dataset = ImageDataset(image_dir=f'/content/drive/MyDrive/Stable_diff/complete_tdata/overfitt_debug/wop', transform=transform)\n","\n","model_path = '/content/drive/MyDrive/Stable_diff/train_vae/models/best_model-epoch:6-loss:0.348914.pth'\n","\n","model = VAE()\n","\n","if os.path.exists(model_path):\n","    print('\\nModel loaded successfully.\\n')\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","\n","model.to(device)\n","\n","# Let's assume:\n","# - you have a 'dataset' that returns a single image each time\n","# - your 'model' (VAE) is loaded with trained weights\n","# - device = 'cuda' or 'cpu'\n","\n","# 1. Pick a random index from the dataset\n","# idx = random.randint(0, len(dataset) - 1)\n","idx = 0\n","\n","# 2. Retrieve the image (shape: (1, H, W) if grayscale)\n","original_image = dataset[idx]  # might be (C,H,W), depends on how your dataset is coded\n","\n","# 3. Send to device and expand batch dimension (N=1)\n","model.eval()\n","with torch.no_grad():\n","    # original_image might be a Tensor of shape (1,H,W). If it's (H,W), wrap or fix dims.\n","    x = original_image.unsqueeze(0).to(device)  # shape (1,1,H,W)\n","    recon, mu, logvar = model(x)\n","    # shape of recon is (1,1,H,W)\n","    print(\"Reconstruction stats:\",\n","      recon.min().item(),\n","      recon.max().item(),\n","      recon.mean().item())\n","\n","\n","# 4. Convert to CPU for plotting\n","x_orig = x.squeeze(0).cpu()     # shape (1,H,W)\n","x_recon = recon.squeeze(0).cpu() # shape (1,H,W)\n","\n","# 5. Plot side by side\n","plt.figure(figsize=(10, 5))\n","\n","plt.subplot(1,2,1)\n","plt.title(\"Original\")\n","# If it's single-channel, pick [0] as the channel dimension, and use cmap='gray'\n","plt.imshow(x_orig[0], cmap='gray')\n","plt.axis('off')\n","\n","plt.subplot(1,2,2)\n","plt.title(\"Reconstructed\")\n","plt.imshow(x_recon[0], cmap='gray')\n","plt.axis('off')\n","\n","plt.show()\n"],"metadata":{"id":"t9q3TvlbSPJm","executionInfo":{"status":"aborted","timestamp":1737875166705,"user_tz":300,"elapsed":5,"user":{"displayName":"Dahirou Dabo Harden","userId":"03178038846286108204"}}},"execution_count":null,"outputs":[]}]}